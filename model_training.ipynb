{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading"
      ],
      "metadata": {
        "id": "MQnu3cDD5P0X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xv4WKHwPUOSB"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "shutil.unpack_archive(\"/content/faces.zip\",\"/content/faces\")\n",
        "\n",
        "data_dir = \"/content/faces/faces\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import sklearn\n",
        "import pickle as pkl\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "neNqr1g7cBN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)\n",
        "print(np.__version__)\n",
        "print(sklearn.__version__)"
      ],
      "metadata": {
        "id": "wE75RN5U6Noz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset = \"training\",\n",
        "    image_size = (256,256),\n",
        "    batch_size = 32,\n",
        "    seed =  123,\n",
        "    shuffle = True,\n",
        ")\n",
        "\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset = \"validation\",\n",
        "    image_size = (256,256),\n",
        "    batch_size = 32,\n",
        "    seed = 123,\n",
        "    shuffle = True,\n",
        ")\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "vPULkwxSdq7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## visualization of a Batch"
      ],
      "metadata": {
        "id": "V7mLg7R75Ld3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for imgs ,labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3,3,i+1)\n",
        "    plt.imshow(imgs[i].numpy().astype(\"int\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "_2U-FL3RgtGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing and augmentation"
      ],
      "metadata": {
        "id": "qYEToiVe3cO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = 256\n",
        "\n",
        "preprocess_input = tf.keras.applications.resnet50.preprocess_input\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.05),\n",
        "    layers.RandomZoom(0.1),\n",
        "    layers.RandomContrast(0.2),\n",
        "])\n",
        "\n",
        "class L2NormLayer(layers.Layer):\n",
        "    def __init__(self, axis=1, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.axis = axis\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.nn.l2_normalize(inputs, axis=self.axis)\n",
        "\n",
        "    def get_config(self):\n",
        "        cfg = super().get_config()\n",
        "        cfg.update({\"axis\": self.axis})\n",
        "        return cfg"
      ],
      "metadata": {
        "id": "By9ws8aV3bDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image, _ in train_ds.take(1):\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  first_image = image[0]\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n",
        "    plt.imshow(augmented_image[0] / 255)\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "id": "OKnIVh8XV2a5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Building"
      ],
      "metadata": {
        "id": "u-rRcy-i6XH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_shape = (img_size,img_size,3)\n",
        "base_model = tf.keras.applications.ResNet50(input_shape=img_shape,include_top=False,weights='imagenet')"
      ],
      "metadata": {
        "id": "uBEAGx8qWwqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_batch, label_batch = next(iter(train_ds))\n",
        "feature_batch = base_model(image_batch)\n",
        "print(feature_batch.shape,image_batch.shape,label_batch.shape)"
      ],
      "metadata": {
        "id": "pqT_Z27AcqHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable=False\n",
        "base_model.summary()"
      ],
      "metadata": {
        "id": "pio0C-y1Xpzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global_avg_layer = layers.GlobalAveragePooling2D()\n",
        "feature_batch_avg = global_avg_layer(feature_batch)\n",
        "\n",
        "print(feature_batch_avg.shape)"
      ],
      "metadata": {
        "id": "0d0B5oMOYWev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_shape"
      ],
      "metadata": {
        "id": "sJIPPYvbd3HS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input and preprocessing in api format\n",
        "\n",
        "inputs = layers.Input(shape=img_shape)\n",
        "x = data_augmentation(inputs)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "## pretrained model\n",
        "\n",
        "x = base_model(x ,training=False)\n",
        "x = global_avg_layer(x)\n",
        "\n",
        "# ann\n",
        "\n",
        "x = layers.Dense(512 ,activation = 'relu')(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.Dense(256,activation = 'relu')(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Dense(128 ,activation = 'relu')(x)\n",
        "\n",
        "x = layers.BatchNormalization()(x)\n",
        "\n",
        "embeddings = L2NormLayer()(x)\n",
        "\n",
        "prediction_layer = layers.Dense(len(train_ds.class_names) ,activation='softmax')(embeddings)\n",
        "\n",
        "embedding_model = tf.keras.Model(inputs,embeddings)\n",
        "classification_model = tf.keras.Model(inputs,prediction_layer)"
      ],
      "metadata": {
        "id": "W3Cd633Kdekq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_model.summary()"
      ],
      "metadata": {
        "id": "97EcF-nTAYOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.0001\n",
        "\n",
        "classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "                             loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                             metrics = [\"accuracy\"]\n",
        ")\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "history = classification_model.fit(\n",
        "    train_ds,\n",
        "    validation_data=test_ds,\n",
        "    epochs=10,\n",
        "    callbacks=[early_stop]\n",
        ")\n"
      ],
      "metadata": {
        "id": "XiphezvMjZ5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')"
      ],
      "metadata": {
        "id": "E9yz83W3vOLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# fine tune"
      ],
      "metadata": {
        "id": "PVx5TAcA5pSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True\n",
        "print(f\"no of layers {len(base_model.layers)}\")"
      ],
      "metadata": {
        "id": "ZWf6ScpY5rzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "st_from = 100\n",
        "for layer in base_model.layers[:st_from]:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "vuaE8Q3y6BaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_model.summary()"
      ],
      "metadata": {
        "id": "TShgTXje64fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr/10),\n",
        "                             loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                             metrics = [\"accuracy\"]\n",
        ")\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "history = classification_model.fit(\n",
        "    train_ds,\n",
        "    validation_data=test_ds,\n",
        "    epochs=20,\n",
        "    callbacks=[early_stop]\n",
        ")"
      ],
      "metadata": {
        "id": "7sI9Oo5t6g-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')"
      ],
      "metadata": {
        "id": "NtkY_pZA5kdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Store Embedding"
      ],
      "metadata": {
        "id": "ecXjNsURBhhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sorted(os.listdir(data_dir))"
      ],
      "metadata": {
        "id": "soSuIkitNENx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_embedding = {}\n",
        "\n",
        "for celeb in os.listdir(data_dir):\n",
        "  temp = []\n",
        "  for file_name in os.listdir(os.path.join(data_dir,celeb)):\n",
        "\n",
        "    img = cv.imread(os.path.join(data_dir,celeb,file_name))\n",
        "    if img is None:\n",
        "      continue\n",
        "    img = cv.cvtColor(img,cv.COLOR_BGR2RGB)\n",
        "\n",
        "    embedding = embedding_model.predict(np.expand_dims(img,axis=0),verbose=0)\n",
        "    temp.append(embedding[0])\n",
        "\n",
        "  if temp:\n",
        "   data_embedding[celeb] = np.mean(temp,axis=0)"
      ],
      "metadata": {
        "id": "FK0YyHHs-WpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Testing**"
      ],
      "metadata": {
        "id": "mdaKLv89RgfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find(embedding):\n",
        "  mx = -1\n",
        "  best_match = \"aryan\"\n",
        "  for celeb,emb in data_embedding.items():\n",
        "    sim = cosine_similarity([embedding],[emb])[0][0]\n",
        "    if sim > mx:\n",
        "      mx = sim\n",
        "      best_match = celeb\n",
        "\n",
        "  return mx,best_match"
      ],
      "metadata": {
        "id": "_6eIktR_TBv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv.imread(\"/content/188_ebfc6465.jpg\")\n",
        "img = cv.cvtColor(img,cv.COLOR_BGR2RGB)\n",
        "embedding = embedding_model.predict(np.expand_dims(img,axis=0),verbose=0)\n",
        "\n",
        "print(find(embedding[0]))"
      ],
      "metadata": {
        "id": "N0jw_HglRa3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model saving"
      ],
      "metadata": {
        "id": "ayxJC4EaWWl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"data_embedding.pkl\",\"wb\") as f:\n",
        "  pkl.dump(data_embedding,f)"
      ],
      "metadata": {
        "id": "cY2T7GzBPa0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model.save(\"face_embedding_model.keras\")"
      ],
      "metadata": {
        "id": "izI7k74sQu5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0vU6dfbX55DH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}